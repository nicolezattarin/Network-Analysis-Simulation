\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Comparing data: the example of two operating systems}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Display distributions}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Confidence intervals}{1}{subsection.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Measured execution times in ms for 100 transactions with the old (left) and new (right) systems. Upper panels represents the scatterplot, while lower panels exhibit the distribution od data by means of histograms. \relax }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:distribution_scatter}{{1}{2}{Measured execution times in ms for 100 transactions with the old (left) and new (right) systems. Upper panels represents the scatterplot, while lower panels exhibit the distribution od data by means of histograms. \relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Cumulative density functions of the distribution of run times for both the systems considered. \relax }}{2}{figure.caption.2}\protected@file@percent }
\newlabel{fig:cdf}{{2}{2}{Cumulative density functions of the distribution of run times for both the systems considered. \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Quantiles of the execution times concerning both the old and new system. Left panel shows the boxplots, while right panel exhibits swarmplots.\relax }}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:boxswarm}{{3}{3}{Quantiles of the execution times concerning both the old and new system. Left panel shows the boxplots, while right panel exhibits swarmplots.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Different visualizations of the reduction times in ms from the older to the more recent version of the operating system. Right panel shows the scatterplot relative to individual data, while right panel shows the distribution. The central plot shows the quantile and the mean (horizontal line), with its confidence interval (dashed lines).\relax }}{3}{figure.caption.4}\protected@file@percent }
\newlabel{fig:reduction}{{4}{3}{Different visualizations of the reduction times in ms from the older to the more recent version of the operating system. Right panel shows the scatterplot relative to individual data, while right panel shows the distribution. The central plot shows the quantile and the mean (horizontal line), with its confidence interval (dashed lines).\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Confidence intervals of mean reduction times for the old and the new version, computation is carried out with different methods. Results show that the mean execution time of the new version is better than the older, while different methods provide similar outcomes.\relax }}{3}{figure.caption.5}\protected@file@percent }
\newlabel{fig:ci_methods}{{5}{3}{Confidence intervals of mean reduction times for the old and the new version, computation is carried out with different methods. Results show that the mean execution time of the new version is better than the older, while different methods provide similar outcomes.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The time evolution of the daily balance provides qualitative informations about the trend, but it does not allow to determine if data are iid.\relax }}{4}{figure.caption.6}\protected@file@percent }
\newlabel{fig:lineplot_joe}{{6}{4}{The time evolution of the daily balance provides qualitative informations about the trend, but it does not allow to determine if data are iid.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Time series:the example of daily balance data}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Simulation analysis}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Uniform distribution}{4}{subsection.3.1}\protected@file@percent }
\newlabel{sec:unif}{{3.1}{4}{Uniform distribution}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Log plots for different values of $h$ (from 1 to 9). It is clear that there is a strong correlation with the previous day, even tough correlations decrease as we consider higher values of h, i.e. larger time shifts.\relax }}{5}{figure.caption.7}\protected@file@percent }
\newlabel{fig:joe_lag_plots}{{7}{5}{Log plots for different values of $h$ (from 1 to 9). It is clear that there is a strong correlation with the previous day, even tough correlations decrease as we consider higher values of h, i.e. larger time shifts.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Autocorrelation plot for all the possible shifts. It provides the correlation coefficient between $y(t)$ and $y(t+h)$ for different shifts.\relax }}{6}{figure.caption.8}\protected@file@percent }
\newlabel{fig:joe_autocorr}{{8}{6}{Autocorrelation plot for all the possible shifts. It provides the correlation coefficient between $y(t)$ and $y(t+h)$ for different shifts.\relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Mean, standard deviation and 95\% CI for a simulation with a sample of 48 elements, for both uniform and normal distribution.\relax }}{6}{table.caption.9}\protected@file@percent }
\newlabel{tab:48}{{1}{6}{Mean, standard deviation and 95\% CI for a simulation with a sample of 48 elements, for both uniform and normal distribution.\relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Simulation with n=48}{6}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{fig:mean_unif}{{9a}{7}{Distribution of the observed means computed on a sample of 48 items, compared with the true mean, represented by the vertical dashed line.\relax }{figure.caption.10}{}}
\newlabel{sub@fig:mean_unif}{{a}{7}{Distribution of the observed means computed on a sample of 48 items, compared with the true mean, represented by the vertical dashed line.\relax }{figure.caption.10}{}}
\newlabel{fig:meanci_unif}{{9b}{7}{CI and corresponding sample mean, computed on 1000 datasets of 48 elements. The vertical dashed line represents the real mean, and it shows how many times it falls into the computed CI.\relax }{figure.caption.10}{}}
\newlabel{sub@fig:meanci_unif}{{b}{7}{CI and corresponding sample mean, computed on 1000 datasets of 48 elements. The vertical dashed line represents the real mean, and it shows how many times it falls into the computed CI.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Results concerning the generation of 1000 datasets, each of which is composed by 48 elements uniformly distributed in $[0,1]$. \relax }}{7}{figure.caption.10}\protected@file@percent }
\newlabel{fig:ci_unif_mean}{{9}{7}{Results concerning the generation of 1000 datasets, each of which is composed by 48 elements uniformly distributed in $[0,1]$. \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Repetition of the experiment 1000 times}{7}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Comparison of results for different values of $n$}{7}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Prediction intervals}{7}{subsubsection.3.1.4}\protected@file@percent }
\newlabel{fig:N_unif_acc}{{10a}{8}{Accuracy of the estimation of the mean for different sizes of the dataset. We observe oscillations, with a general increasing trend, as $n$ increases, in particular the curve gets more stable for high values of $n$.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:N_unif_acc}{{a}{8}{Accuracy of the estimation of the mean for different sizes of the dataset. We observe oscillations, with a general increasing trend, as $n$ increases, in particular the curve gets more stable for high values of $n$.\relax }{figure.caption.11}{}}
\newlabel{fig:N_unif_var}{{10b}{8}{Variance and its CI for different values of $n$. As we increase the size of the dataset, our uncertainty on the estimate of the variance decreases.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:N_unif_var}{{b}{8}{Variance and its CI for different values of $n$. As we increase the size of the dataset, our uncertainty on the estimate of the variance decreases.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Accuracy of the mean, computed as $\qopname  \relax o{log}(1/\epsilon )$ where $\epsilon =|\mu _n-\mu _{real}|$, and the CI of the variance for different values of $n$\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:N_unif}{{10}{8}{Accuracy of the mean, computed as $\log (1/\epsilon )$ where $\epsilon =|\mu _n-\mu _{real}|$, and the CI of the variance for different values of $n$\relax }{figure.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces CI computed with the standard method for $iid$ data, based on order statistic, and with bootstrap. We consider two datasets of 1000 elements, one with normal and one with uniform distribution. \relax }}{8}{table.caption.12}\protected@file@percent }
\newlabel{tab:pi}{{2}{8}{CI computed with the standard method for $iid$ data, based on order statistic, and with bootstrap. We consider two datasets of 1000 elements, one with normal and one with uniform distribution. \relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Normal distribution}{8}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Simulation with n=48}{8}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Repetition of the experiment 1000 times}{8}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{fig:mean_norm}{{11a}{9}{Distribution of the observed means computed on a sample of 48 items, compared with the true mean, represented by the vertical dashed line.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:mean_norm}{{a}{9}{Distribution of the observed means computed on a sample of 48 items, compared with the true mean, represented by the vertical dashed line.\relax }{figure.caption.13}{}}
\newlabel{fig:meanci_norm}{{11b}{9}{CI and corresponding sample mean, computed on 1000 datasets of 48 elements. The vertical dashed line represents the real mean, and it shows how many times it falls into the computed CI.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:meanci_norm}{{b}{9}{CI and corresponding sample mean, computed on 1000 datasets of 48 elements. The vertical dashed line represents the real mean, and it shows how many times it falls into the computed CI.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Results concerning the generation of 1000 datasets, each of which is composed by 48 elements normally distributed with zero mean and unitary variance. \relax }}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:ci_norm_mean}{{11}{9}{Results concerning the generation of 1000 datasets, each of which is composed by 48 elements normally distributed with zero mean and unitary variance. \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Comparison of results for different values of $n$}{9}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Prediction intervals}{9}{subsubsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Order statistic}{9}{section.4}\protected@file@percent }
\newlabel{fig:N_norm_acc}{{12a}{10}{Accuracy of the estimation of the mean for different sizes of the dataset. We observe an irregular increasing trend, in particular the curve gets more stable for high values of $n$.\relax }{figure.caption.14}{}}
\newlabel{sub@fig:N_norm_acc}{{a}{10}{Accuracy of the estimation of the mean for different sizes of the dataset. We observe an irregular increasing trend, in particular the curve gets more stable for high values of $n$.\relax }{figure.caption.14}{}}
\newlabel{fig:N_norm_var}{{12b}{10}{Variance and its CI for different values of $n$. As we increase the size of the dataset, our uncertainty on the estimate of the variance decreases.\relax }{figure.caption.14}{}}
\newlabel{sub@fig:N_norm_var}{{b}{10}{Variance and its CI for different values of $n$. As we increase the size of the dataset, our uncertainty on the estimate of the variance decreases.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Accuracy of the mean, computed as $\qopname  \relax o{log}(1/\epsilon )$ where $\epsilon =|\mu _n-\mu _{real}|$, and the CI of the variance for different values of $n$\relax }}{10}{figure.caption.14}\protected@file@percent }
\newlabel{fig:N_norm}{{12}{10}{Accuracy of the mean, computed as $\log (1/\epsilon )$ where $\epsilon =|\mu _n-\mu _{real}|$, and the CI of the variance for different values of $n$\relax }{figure.caption.14}{}}
